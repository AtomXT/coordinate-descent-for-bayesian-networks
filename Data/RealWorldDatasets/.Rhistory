# pearson correlation
pearsoncorest[[ii]] <- mymgest(datmat[[ii]], method="pearson", tunepar=pvalthresh)
pearsoncorerr[ii,1:2] <- calcesterr(trueadj=adjmat_mg[[ii]], estadj=pearsoncorest[[ii]])
pearsoncorerr[ii,3:4] <- calcesterr(trueadj=adjmat_dag[[ii]], estadj=pearsoncorest[[ii]])
# kendal's tau
kendalcorest[[ii]] <- mymgest(datmat[[ii]], method="kendal", tunepar=pvalthresh)
kendalcorerr[ii,1:2] <- calcesterr(trueadj=adjmat_mg[[ii]], estadj=kendalcorest[[ii]])
kendalcorerr[ii,3:4] <- calcesterr(trueadj=adjmat_dag[[ii]], estadj=kendalcorest[[ii]])
}
library(igraph)
library(psych)
##############
### 03/06/2022
### Estimation of moral graph for all real-world nets
##############
## function to estimate moral graph
mymgest <- function(dat, method=c("pearson", "kendal"), tunepar=NULL){
n <- nrow(dat)
p <- ncol(dat)
if(method == "pearson"){
#if (is.null(tunepar)) tunepar <- 0.2
mgest <- cor(dat, method="pearson")
mgest <- r2t(mgest, n)  ##t-test based from correlations
pvals <- (1-pt(mgest,n-2))*2  ##p-values for t-test
mgest <- 1*(pvals < tunepar); diag(mgest) <- 0
}
if(method == "kendal"){
#if (is.null(tunepar)) tunepar <- 0.2
mgest <- cor(dat, method="kendal")
mgest <- sin((pi/2)*mgest)  ##sin transform the kendal taus
mgest <- r2t(mgest, n)  ##t-test based from correlations
pvals <- (1-pt(mgest,n-2))*2  ##p-values for t-test
mgest <- 1*(pvals < tunepar); diag(mgest) <- 0
}
return(mgest)
}
## function to get graph object and adjacency matrix
adjmatfromelist <- function(elist){
gobj <- graph_from_edgelist(as.matrix(elist), directed="FALSE")
adjmat <- as.matrix(get.adjacency(gobj))
return(adjmat)
}
## function to calculate errors
calcesterr <- function(trueadj, estadj){
fp <- sum(1*((estadj - trueadj) > 0)) / 2
fn <- sum(1*((trueadj - estadj) > 0)) / 2
return(c(fp,fn))
}
##
## estimate the graphs etc
##
# setwd('/Users/ashojaie/Dropbox/HasanManzour/SeconPaper-SimgeAli/RealWorldDatasetsHHWu/')
setwd('E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsHHWu\\NonEqVarData\\')
##read the folder names
foldernames <- list.files(getwd())
foldernames <- foldernames[c(2:10,1)]  ## sort the folder names from 1 to 10
errors2report <- c("FP_mg", "FN_mg", "FP_dag", "FN_dag")
datnames <- datmat <- vector("list", length(foldernames))
adjmat_mg <- adjmat_dag <- vector("list", length(foldernames))
pearsoncorest <- kendalcorest <- vector("list", length(foldernames))
pearsoncorerr <- kendalcorerr <- matrix(NA, length(foldernames), length(errors2report))
rownames(pearsoncorerr) <- rownames(kendalcorerr) <- foldernames
colnames(pearsoncorerr) <- colnames(kendalcorerr) <- errors2report
dims <- matrix(NA, length(datnames), 2)
colnames(dims) <- c("n","p"); rownames(dims) <- foldernames
pvalthresh <- 0.05
for (ii in 1:length(foldernames)){
# for (ii in 1:2){
datfolder <- datnames[[ii]] <- foldernames[ii]
datfilename <- list.files(paste(datfolder,"/",sep="")) #, pattern="^[Sparse_DAG_Data]")
datmat[[ii]] <- read.table(paste(datfolder,"/",list.files(datfolder,"n_100_iter_1")[1],sep=""), sep=",")
dims[ii,] <- c(nrow(datmat[[ii]]), ncol(datmat[[ii]]))
elist_mg <- read.table(paste(datfolder,"/",list.files(datfolder,"Moral"),sep=""), sep=",")
adjmat_mg[[ii]] <- adjmatfromelist(elist_mg)
elist_dag <- read.table(paste(datfolder,"/",list.files(datfolder,"Original"),sep=""), sep=",")
adjmat_dag[[ii]] <- adjmatfromelist(elist_dag)
# pearson correlation
pearsoncorest[[ii]] <- mymgest(datmat[[ii]], method="pearson", tunepar=pvalthresh)
pearsoncorerr[ii,1:2] <- calcesterr(trueadj=adjmat_mg[[ii]], estadj=pearsoncorest[[ii]])
pearsoncorerr[ii,3:4] <- calcesterr(trueadj=adjmat_dag[[ii]], estadj=pearsoncorest[[ii]])
# kendal's tau
kendalcorest[[ii]] <- mymgest(datmat[[ii]], method="kendal", tunepar=pvalthresh)
kendalcorerr[ii,1:2] <- calcesterr(trueadj=adjmat_mg[[ii]], estadj=kendalcorest[[ii]])
kendalcorerr[ii,3:4] <- calcesterr(trueadj=adjmat_dag[[ii]], estadj=kendalcorest[[ii]])
}
nedges <- dims[,2] * (dims[,2] - 1) / 2
(pearsoncorerr <- cbind(nedges, pearsoncorerr))
(kendalcorerr <- cbind(nedges, kendalcorerr))
# ## write the estimated graphs (for Pearson correlation) into file
# for(ii in 1:length(foldernames)){
#   write.table(pearsoncorest[[ii]],
#               file=paste(foldernames[ii], "/", "mgest_PearsonCorEst_new.txt",sep=""),
#               sep=",", row.names=FALSE, col.names=FALSE)
# }
library(igraph)
library(psych)
##############
### 03/06/2022
### Estimation of moral graph for all real-world nets
##############
## function to estimate moral graph
mymgest <- function(dat, method=c("pearson", "kendal"), tunepar=NULL){
n <- nrow(dat)
p <- ncol(dat)
if(method == "pearson"){
#if (is.null(tunepar)) tunepar <- 0.2
mgest <- cor(dat, method="pearson")
mgest <- r2t(mgest, n)  ##t-test based from correlations
pvals <- (1-pt(mgest,n-2))*2  ##p-values for t-test
mgest <- 1*(pvals < tunepar); diag(mgest) <- 0
}
if(method == "kendal"){
#if (is.null(tunepar)) tunepar <- 0.2
mgest <- cor(dat, method="kendal")
mgest <- sin((pi/2)*mgest)  ##sin transform the kendal taus
mgest <- r2t(mgest, n)  ##t-test based from correlations
pvals <- (1-pt(mgest,n-2))*2  ##p-values for t-test
mgest <- 1*(pvals < tunepar); diag(mgest) <- 0
}
return(mgest)
}
## function to get graph object and adjacency matrix
adjmatfromelist <- function(elist){
gobj <- graph_from_edgelist(as.matrix(elist), directed="FALSE")
adjmat <- as.matrix(get.adjacency(gobj))
return(adjmat)
}
## function to calculate errors
calcesterr <- function(trueadj, estadj){
fp <- sum(1*((estadj - trueadj) > 0)) / 2
fn <- sum(1*((trueadj - estadj) > 0)) / 2
return(c(fp,fn))
}
##
## estimate the graphs etc
##
# setwd('/Users/ashojaie/Dropbox/HasanManzour/SeconPaper-SimgeAli/RealWorldDatasetsHHWu/')
setwd('E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsHHWu\\NonEqVarData\\')
##read the folder names
foldernames <- list.files(getwd())
foldernames <- foldernames[c(2:10,1)]  ## sort the folder names from 1 to 10
errors2report <- c("FP_mg", "FN_mg", "FP_dag", "FN_dag")
datnames <- datmat <- vector("list", length(foldernames))
adjmat_mg <- adjmat_dag <- vector("list", length(foldernames))
pearsoncorest <- kendalcorest <- vector("list", length(foldernames))
pearsoncorerr <- kendalcorerr <- matrix(NA, length(foldernames), length(errors2report))
rownames(pearsoncorerr) <- rownames(kendalcorerr) <- foldernames
colnames(pearsoncorerr) <- colnames(kendalcorerr) <- errors2report
dims <- matrix(NA, length(datnames), 2)
colnames(dims) <- c("n","p"); rownames(dims) <- foldernames
pvalthresh <- 0.01
for (ii in 1:length(foldernames)){
# for (ii in 1:2){
datfolder <- datnames[[ii]] <- foldernames[ii]
datfilename <- list.files(paste(datfolder,"/",sep="")) #, pattern="^[Sparse_DAG_Data]")
datmat[[ii]] <- read.table(paste(datfolder,"/",list.files(datfolder,"n_100_iter_1")[1],sep=""), sep=",")
dims[ii,] <- c(nrow(datmat[[ii]]), ncol(datmat[[ii]]))
elist_mg <- read.table(paste(datfolder,"/",list.files(datfolder,"Moral"),sep=""), sep=",")
adjmat_mg[[ii]] <- adjmatfromelist(elist_mg)
elist_dag <- read.table(paste(datfolder,"/",list.files(datfolder,"Original"),sep=""), sep=",")
adjmat_dag[[ii]] <- adjmatfromelist(elist_dag)
# pearson correlation
pearsoncorest[[ii]] <- mymgest(datmat[[ii]], method="pearson", tunepar=pvalthresh)
pearsoncorerr[ii,1:2] <- calcesterr(trueadj=adjmat_mg[[ii]], estadj=pearsoncorest[[ii]])
pearsoncorerr[ii,3:4] <- calcesterr(trueadj=adjmat_dag[[ii]], estadj=pearsoncorest[[ii]])
# kendal's tau
kendalcorest[[ii]] <- mymgest(datmat[[ii]], method="kendal", tunepar=pvalthresh)
kendalcorerr[ii,1:2] <- calcesterr(trueadj=adjmat_mg[[ii]], estadj=kendalcorest[[ii]])
kendalcorerr[ii,3:4] <- calcesterr(trueadj=adjmat_dag[[ii]], estadj=kendalcorest[[ii]])
}
nedges <- dims[,2] * (dims[,2] - 1) / 2
(pearsoncorerr <- cbind(nedges, pearsoncorerr))
(kendalcorerr <- cbind(nedges, kendalcorerr))
# ## write the estimated graphs (for Pearson correlation) into file
# for(ii in 1:length(foldernames)){
#   write.table(pearsoncorest[[ii]],
#               file=paste(foldernames[ii], "/", "mgest_PearsonCorEst_new.txt",sep=""),
#               sep=",", row.names=FALSE, col.names=FALSE)
# }
pearsoncorest[[1]]
sum(pearsoncorest[[1]])
sum(pearsoncorest[[1]] * true_graph_adj)
sum(pearsoncorest[[2]] * true_graph_adj)
View(pearsoncorest)
sim(true_graph_adj)
dim(true_graph_adj)
View(pearsoncorest)
sum(pearsoncorest[[10]] * true_graph_adj)
runif(10,1,10)/10
library(igraph)
library(MASS)
data.path = "E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsTXu\\"
setwd(data.path)
filenames <- list.files(data.path)
filenames
ii
ii = 1
fname = filenames[ii]
## read the edge list
filename <- list.files(paste(filepath, fname, sep="/"))
filename <- list.files(paste(filepath, fname, sep="\\"))
fname
paste(filepath, fname, sep="\\")
list.files(paste(data.path, fname, sep="\\"))
list.files(paste(data.path, fname, sep="\\"),"Original")
ii = 1
filenames <- list.files(data.path)
data.path = "E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsTXu\\"
setwd(data.path)
filenames <- list.files(data.path)
filename <- list.files(paste(data.path, fname, sep="\\"),"Sparse_Original")
fname = filenames[ii]
## read the edge list
filename <- list.files(paste(data.path, fname, sep="\\"),"Sparse_Original")
elist <- read.csv(paste(filepath, fname, filename, sep="\\"))
fname = filenames[ii]
## read the edge list
filename <- list.files(paste(data.path, fname, sep="\\"),"Sparse_Original")
elist <- read.csv(paste(data.path, fname, filename, sep="\\"))
View(elist)
fname
## create a graph object and get adjacency matrix
gg <- graph_from_edgelist(as.matrix(elist))
adjmat <- t(as.matrix(get.adjacency(gg)))
nv <- ncol(adjmat)
## add weights to the adjacency matrix and obtain influence matrix
set.seed(ii)
adjmat_wgtd <- adjmat *
matrix(sample(eweights, nv*nv, replace=T), nv, nv)
eweights <- c(-0.8, -0.6, 0.6, 0.8)
sigvec <- c(0.5, 1, 1.5)
nsamples <- 500
ndata <- 10
## create a graph object and get adjacency matrix
gg <- graph_from_edgelist(as.matrix(elist))
adjmat <- t(as.matrix(get.adjacency(gg)))
nv <- ncol(adjmat)
## add weights to the adjacency matrix and obtain influence matrix
set.seed(ii)
adjmat_wgtd <- adjmat *
matrix(sample(eweights, nv*nv, replace=T), nv, nv)
Ip <- diag(1, nv, nv)
infmat <- solve(Ip - adjmat_wgtd)
## covariance matrix for random noise with non-equal variance
## using formulas in Shojaie & Michailidis (2010)
set.seed(ii)
covmat <- diag(sample(sigvec, nv, replace=T))
covmat <- infmat %*% covmat %*% t(infmat)
## generate data and write it into the same folder
for(jj in 1:ndata){
set.seed(jj)
datmat <- mvrnorm(n=nsamples, mu=rep(0,nv), Sigma=covmat)
datfilename <- paste0(
paste("data", fname, "n", nsamples, "iter", jj, sep="_"), ".csv")
datfilename <- paste(filepath, fname, datfilename, sep="/")
write.table(datmat, datfilename, sep = ",",
row.names=FALSE, col.names=FALSE)
}
## create a graph object and get adjacency matrix
gg <- graph_from_edgelist(as.matrix(elist))
adjmat <- t(as.matrix(get.adjacency(gg)))
nv <- ncol(adjmat)
## add weights to the adjacency matrix and obtain influence matrix
set.seed(ii)
adjmat_wgtd <- adjmat *
matrix(sample(eweights, nv*nv, replace=T), nv, nv)
Ip <- diag(1, nv, nv)
infmat <- solve(Ip - adjmat_wgtd)
## covariance matrix for random noise with non-equal variance
## using formulas in Shojaie & Michailidis (2010)
set.seed(ii)
covmat <- diag(sample(sigvec, nv, replace=T))
covmat <- infmat %*% covmat %*% t(infmat)
## generate data and write it into the same folder
for(jj in 1:ndata){
set.seed(jj)
datmat <- mvrnorm(n=nsamples, mu=rep(0,nv), Sigma=covmat)
datfilename <- paste0(
paste("data", fname, "n", nsamples, "iter", jj, sep="_"), ".csv")
datfilename <- paste(data.path, fname, datfilename, sep="/")
write.table(datmat, datfilename, sep = ",",
row.names=FALSE, col.names=FALSE)
}
##############
### 08/27/2023
### Generate 10 datasets for each real world network from 1dsep to 12hepar
### Most part of this script is copied from "datfromgraph_unequalvar.R"
##############
library(igraph)
library(MASS)
data.path = "E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsTXu\\"
setwd(data.path)
filenames <- list.files(data.path)
eweights <- c(-0.8, -0.6, 0.6, 0.8)
sigvec <- c(0.5, 1, 1.5)
nsamples <- 500
ndata <- 10
#ii=3
for(ii in 1:length(filenames)){
fname = filenames[ii]
## read the edge list
filename <- list.files(paste(data.path, fname, sep="\\"),"Sparse_Original")
elist <- read.csv(paste(data.path, fname, filename, sep="\\"))
## create a graph object and get adjacency matrix
gg <- graph_from_edgelist(as.matrix(elist))
adjmat <- t(as.matrix(get.adjacency(gg)))
nv <- ncol(adjmat)
## add weights to the adjacency matrix and obtain influence matrix
set.seed(ii)
adjmat_wgtd <- adjmat *
matrix(sample(eweights, nv*nv, replace=T), nv, nv)
Ip <- diag(1, nv, nv)
infmat <- solve(Ip - adjmat_wgtd)
## covariance matrix for random noise with non-equal variance
## using formulas in Shojaie & Michailidis (2010)
set.seed(ii)
covmat <- diag(sample(sigvec, nv, replace=T))
covmat <- infmat %*% covmat %*% t(infmat)
## generate data and write it into the same folder
for(jj in 1:ndata){
set.seed(jj)
datmat <- mvrnorm(n=nsamples, mu=rep(0,nv), Sigma=covmat)
datfilename <- paste0(
paste("data", fname, "n", nsamples, "iter", jj, sep="_"), ".csv")
datfilename <- paste(data.path, fname, datfilename, sep="/")
write.table(datmat, datfilename, sep = ",",
row.names=FALSE, col.names=FALSE)
}
}
dataset.folder <- "E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsTXu\\"
filenames <- list.files(data.path)
filenames
c(1:10)
paste0("_",3)
list.files(paste(dataset.folder,dataset.name,sep="\\"), "n_500_iter_", kk)[1]
kk = 1
dataset.name
dataset.name = filenames[1]
list.files(paste(dataset.folder,dataset.name,sep="\\"), "n_500_iter_", kk)[1]
list.files(paste(dataset.folder,dataset.name,sep="\\"), "n_500_iter_", 2)[1]
list.files(paste(dataset.folder,dataset.name,sep="\\"), "n_500_iter_", 3)[1]
list.files(paste(dataset.folder,dataset.name,sep="\\"), paste0("n_500_iter_", 3))[1]
list.files(paste(dataset.folder,dataset.name,sep="\\"), paste0("n_500_iter_", 6))[1]
data.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), paste0("n_500_iter_", kk))[1]
true.graph.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "Original")
# mgest.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "mgest_PearsonCorEst.txt")
true.moral.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "Sparse_Moral")
data = read.csv(paste(dataset.folder,dataset.name, data.file, sep="\\"), header=FALSE)
true_graph = read.table(paste(dataset.folder,dataset.name,true.graph.file, sep="\\"), header=FALSE, sep=",")
# moral_graph = read.table(paste(dataset.folder,dataset.name,mgest.file, sep="\\"), header=FALSE, sep=",")
true_moral = read.table(paste(dataset.folder,dataset.name,true.moral.file, sep="\\"), header=FALSE, sep=",")
S = cov(data)
n = 500
p = dim(data)[2]
m = dim(true_graph)[1]
true_graph_adj = matrix(0, p, p)
true_moral_adj = matrix(0, p, p)
# moral_graph_adj = matrix(0, p, p)
for (ii in 1:m) {
true_graph_adj[true_graph[ii,1], true_graph[ii,2]] = 1
}
for (ii in 1:dim(true_moral)[1]){
true_moral_adj[true_moral[ii,1], true_moral[ii,2]] = 1
}
ans = glasso(S,log(p)/n)
theta = ans$wi
theta[abs(theta) < 0.15] = 0
diag(theta) = 0
temp = sign(abs(theta))
sum(temp * true_graph_adj)
sum(moral_graph * true_graph_adj)
sum(temp * true_graph_adj)
sum(true_graph_adj)
sum(true_moral_adj)
sum(temp)
paste0("superstructure_glasso_","iter_", 1, ".txt")
##############
### 08/24/2023
### Estimation of moral graph for all real-world nets using graphical lasso
##############
library(glasso)
dataset.folder <- "E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsTXu\\"
filenames <- list.files(data.path)
for (dataset.name in filenames) {
for (kk in c(1:10)) {
}
data.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), paste0("n_500_iter_", kk))[1]
true.graph.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "Original")
# mgest.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "mgest_PearsonCorEst.txt")
true.moral.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "Sparse_Moral")
data = read.csv(paste(dataset.folder,dataset.name, data.file, sep="\\"), header=FALSE)
true_graph = read.table(paste(dataset.folder,dataset.name,true.graph.file, sep="\\"), header=FALSE, sep=",")
# moral_graph = read.table(paste(dataset.folder,dataset.name,mgest.file, sep="\\"), header=FALSE, sep=",")
true_moral = read.table(paste(dataset.folder,dataset.name,true.moral.file, sep="\\"), header=FALSE, sep=",")
S = cov(data)
n = 500
p = dim(data)[2]
m = dim(true_graph)[1]
true_graph_adj = matrix(0, p, p)
true_moral_adj = matrix(0, p, p)
# moral_graph_adj = matrix(0, p, p)
for (ii in 1:m) {
true_graph_adj[true_graph[ii,1], true_graph[ii,2]] = 1
}
for (ii in 1:dim(true_moral)[1]){
true_moral_adj[true_moral[ii,1], true_moral[ii,2]] = 1
}
ans = glasso(S,log(p)/n)
theta = ans$wi
theta[abs(theta) < 0.15] = 0
diag(theta) = 0
temp = sign(abs(theta))
superstructure.name = paste0("superstructure_glasso_","iter_", kk, ".txt")
write.table(temp,paste(dataset.folder,dataset.name,superstructure.name,sep="\\"),sep=",",row.names = FALSE,col.names=FALSE)
}
# sum(temp * true_graph_adj)
# sum(moral_graph * true_graph_adj)
# sum(true_graph_adj)
# sum(true_moral_adj)
#
# sum(temp)
# sum(moral_graph)
##############
# res = hc(data)
# moral1 = moral(res)
# moral1_adj = amat(moral1)
# sum(moral1_adj * true_graph_adj)
# sum(moral1_adj)
#############
# res = EqVarDAG_TD(data)
# res$adj[res$adj == TRUE] = 1
# e = graph_from_adjacency_matrix(res$adj)
# ee = igraph.to.graphNEL(e)
# ee = as.bn(ee)
#
# moral1 = moral(ee)
# moral1_adj = amat(moral1)
# sum(moral1_adj * true_graph_adj)
# sum(moral1_adj)
#######
#
# moral2_adj = moral_graph * temp
# sum(moral2_adj * true_graph_adj)
# sum(moral2_adj)
##############
### 08/24/2023
### Estimation of moral graph for all real-world nets using graphical lasso
##############
library(glasso)
dataset.folder <- "E:\\Northwestern\\Research\\independent study 1\\dag\\gurobi\\MIPDAGextentions\\RealWorldDatasetsTXu\\"
filenames <- list.files(data.path)
for (dataset.name in filenames) {
for (kk in c(1:10)) {
data.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), paste0("n_500_iter_", kk))[1]
true.graph.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "Original")
# mgest.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "mgest_PearsonCorEst.txt")
true.moral.file = list.files(paste(dataset.folder,dataset.name,sep="\\"), "Sparse_Moral")
data = read.csv(paste(dataset.folder,dataset.name, data.file, sep="\\"), header=FALSE)
true_graph = read.table(paste(dataset.folder,dataset.name,true.graph.file, sep="\\"), header=FALSE, sep=",")
# moral_graph = read.table(paste(dataset.folder,dataset.name,mgest.file, sep="\\"), header=FALSE, sep=",")
true_moral = read.table(paste(dataset.folder,dataset.name,true.moral.file, sep="\\"), header=FALSE, sep=",")
S = cov(data)
n = 500
p = dim(data)[2]
m = dim(true_graph)[1]
true_graph_adj = matrix(0, p, p)
true_moral_adj = matrix(0, p, p)
# moral_graph_adj = matrix(0, p, p)
for (ii in 1:m) {
true_graph_adj[true_graph[ii,1], true_graph[ii,2]] = 1
}
for (ii in 1:dim(true_moral)[1]){
true_moral_adj[true_moral[ii,1], true_moral[ii,2]] = 1
}
ans = glasso(S,log(p)/n)
theta = ans$wi
theta[abs(theta) < 0.15] = 0
diag(theta) = 0
temp = sign(abs(theta))
superstructure.name = paste0("superstructure_glasso_","iter_", kk, ".txt")
write.table(temp,paste(dataset.folder,dataset.name,superstructure.name,sep="\\"),sep=",",row.names = FALSE,col.names=FALSE)
}
}
# sum(temp * true_graph_adj)
# sum(moral_graph * true_graph_adj)
# sum(true_graph_adj)
# sum(true_moral_adj)
#
# sum(temp)
# sum(moral_graph)
##############
# res = hc(data)
# moral1 = moral(res)
# moral1_adj = amat(moral1)
# sum(moral1_adj * true_graph_adj)
# sum(moral1_adj)
#############
# res = EqVarDAG_TD(data)
# res$adj[res$adj == TRUE] = 1
# e = graph_from_adjacency_matrix(res$adj)
# ee = igraph.to.graphNEL(e)
# ee = as.bn(ee)
#
# moral1 = moral(ee)
# moral1_adj = amat(moral1)
# sum(moral1_adj * true_graph_adj)
# sum(moral1_adj)
#######
#
# moral2_adj = moral_graph * temp
# sum(moral2_adj * true_graph_adj)
# sum(moral2_adj)
